# ADD THIS TO YOUR EXISTING PIPELINE (INSERT AFTER deploy-api JOB)

  setup-monitoring:
    name: üìä Setup Monitoring
    runs-on: ubuntu-latest
    needs: [deploy-s3, deploy-api]
    if: success() && github.event.inputs.deployment_env != 'development'
    outputs:
      dashboard-url: ${{ steps.monitor.outputs.dashboard_url }}
      alarm-count: ${{ steps.monitor.outputs.alarm_count }}
      
    steps:
    - uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: üìä Create Monitoring
      id: monitor
      run: |
        LAMBDA_FUNCTION="${{ env.LAMBDA_FUNCTION }}"
        API_GATEWAY="${{ env.API_GATEWAY }}"
        DASHBOARD_NAME="serverless-dashboard-${{ github.run_id }}"
        
        # Create CloudWatch Alarms
        aws cloudwatch put-metric-alarm \
          --alarm-name "lambda-errors-${{ github.run_id }}" \
          --alarm-description "Lambda errors" \
          --metric-name Errors --namespace AWS/Lambda \
          --statistic Sum --period 300 --threshold 1 \
          --comparison-operator GreaterThanOrEqualToThreshold \
          --evaluation-periods 1 \
          --dimensions Name=FunctionName,Value=$LAMBDA_FUNCTION || true
        
        aws cloudwatch put-metric-alarm \
          --alarm-name "api-5xx-errors-${{ github.run_id }}" \
          --alarm-description "API 5XX errors" \
          --metric-name 5XXError --namespace AWS/ApiGateway \
          --statistic Sum --period 300 --threshold 1 \
          --comparison-operator GreaterThanOrEqualToThreshold \
          --evaluation-periods 1 \
          --dimensions Name=ApiName,Value=$API_GATEWAY || true
        
        # Create Dashboard
        DASHBOARD_BODY='{
          "widgets": [
            {
              "type": "metric", "x": 0, "y": 0, "width": 12, "height": 6,
              "properties": {
                "metrics": [
                  ["AWS/Lambda", "Duration", "FunctionName", "'$LAMBDA_FUNCTION'"],
                  [".", "Errors", ".", "."],
                  [".", "Invocations", ".", "."]
                ],
                "period": 300, "stat": "Average", "region": "'${{ env.AWS_REGION }}'",
                "title": "Lambda Metrics", "view": "timeSeries"
              }
            },
            {
              "type": "metric", "x": 12, "y": 0, "width": 12, "height": 6,
              "properties": {
                "metrics": [
                  ["AWS/ApiGateway", "Count", "ApiName", "'$API_GATEWAY'"],
                  [".", "Latency", ".", "."],
                  [".", "5XXError", ".", "."]
                ],
                "period": 300, "stat": "Average", "region": "'${{ env.AWS_REGION }}'",
                "title": "API Gateway Metrics", "view": "timeSeries"
              }
            }
          ]
        }'
        
        if aws cloudwatch put-dashboard --dashboard-name "$DASHBOARD_NAME" --dashboard-body "$DASHBOARD_BODY"; then
          DASHBOARD_URL="https://${{ env.AWS_REGION }}.console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#dashboards:name=$DASHBOARD_NAME"
          echo "dashboard_url=$DASHBOARD_URL" >> $GITHUB_OUTPUT
          echo "alarm_count=2" >> $GITHUB_OUTPUT
          echo "‚úÖ Monitoring setup complete: $DASHBOARD_URL"
        else
          echo "dashboard_url=" >> $GITHUB_OUTPUT
          echo "alarm_count=0" >> $GITHUB_OUTPUT
          echo "‚ö†Ô∏è Monitoring setup failed"
        fi

# UPDATE YOUR verify-deployment JOB NEEDS:
# Change: needs: [deploy-s3, deploy-api]
# To: needs: [deploy-s3, deploy-api, setup-monitoring]

# UPDATE YOUR generate-report JOB NEEDS:
# Change: needs: [build-react, deploy-s3, deploy-api, verify-deployment]  
# To: needs: [build-react, deploy-s3, deploy-api, setup-monitoring, verify-deployment]

# ADD THESE LINES TO YOUR DEPLOYMENT REPORT GENERATION (in generate-report job):
# Add after VERIFICATION_STATUS line:
        DASHBOARD_URL="${{ needs.setup-monitoring.outputs.dashboard-url || '' }}"
        ALARM_COUNT="${{ needs.setup-monitoring.outputs.alarm-count || '0' }}"

# ADD THIS TO YOUR MARKDOWN REPORT (in the deployment-report.md section):
        ### üìä Monitoring Dashboard
        $(if [[ -n "$DASHBOARD_URL" ]]; then
          echo "- **CloudWatch Dashboard**: [View Live Metrics]($DASHBOARD_URL)"
          echo "- **Active Alarms**: $ALARM_COUNT CloudWatch alarms"
          echo "- **Metrics**: Lambda performance, API Gateway stats, error rates"
        else
          echo "- **Status**: Monitoring setup skipped or failed"
        fi)

# ADD THIS TO YOUR HTML REPORT (in the deployment-report.html section):
                    $(if [[ -n "$DASHBOARD_URL" ]]; then
                      echo '<div class="url-item">'
                      echo '<strong>üìä Monitoring Dashboard:</strong><br>'
                      echo '<a href="'"$DASHBOARD_URL"'" target="_blank">View Live Metrics & Performance</a>'
                      echo '</div>'
                    fi)

# UPDATE CLEANUP JOB (add monitoring cleanup):
# Add these lines to cleanup-resources job after IAM cleanup:
        
        # Monitoring cleanup
        if [[ "$MONITORING_ENABLED" != "false" ]]; then
          aws cloudwatch delete-dashboards --dashboard-names "serverless-dashboard-${{ github.run_id }}" 2>/dev/null || true
          aws cloudwatch delete-alarms --alarm-names \
            "lambda-errors-${{ github.run_id }}" \
            "api-5xx-errors-${{ github.run_id }}" 2>/dev/null || true
        fi
